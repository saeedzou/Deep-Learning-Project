{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedzou/Deep-Learning-Project/blob/main/Phase%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efwLVBYQo76z",
        "outputId": "f56a33c1-f860-4a7b-e6b5-f7ce966ad9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MSCTD'...\n",
            "remote: Enumerating objects: 1217, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 1217 (delta 13), reused 7 (delta 3), pack-reused 1190\u001b[K\n",
            "Receiving objects: 100% (1217/1217), 102.24 MiB | 22.99 MiB/s, done.\n",
            "Resolving deltas: 100% (617/617), done.\n",
            "Updating files: 100% (934/934), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-43sQYxSCsCIxQjOCAS-H4dDI6c2zgi8\n",
            "To: /content/train_ende.zip\n",
            "100% 2.90G/2.90G [00:17<00:00, 167MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k-m84NIuOOTbXjn6ELwj1qBeH7jsN6IO\n",
            "To: /content/dev.zip\n",
            "100% 638M/638M [00:02<00:00, 236MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0Gg-qpqJpNfLPU7DT81UaFgwu8DVn15\n",
            "To: /content/test.zip\n",
            "100% 641M/641M [00:03<00:00, 180MB/s]\n",
            "replace train_ende/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: mv: cannot move 'train_ende' to 'train/train_ende': Directory not empty\n",
            "mkdir: cannot create directory ‘train/image’: File exists\n",
            "mkdir: cannot create directory ‘dev/image’: File exists\n",
            "mkdir: cannot create directory ‘test/image’: File exists\n",
            "mv: cannot stat 'train/*.jpg': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# This block downloads and preprocesses the needed data for the project\n",
        "!git clone https://github.com/XL2248/MSCTD\n",
        "!cp MSCTD/MSCTD_data/ende/eng* .\n",
        "!cp MSCTD/MSCTD_data/ende/ima* .\n",
        "!cp MSCTD/MSCTD_data/ende/sent* .\n",
        "!rm -rf MSCTD\n",
        "!pip -q install --upgrade --no-cache-dir gdown\n",
        "!gdown 1-43sQYxSCsCIxQjOCAS-H4dDI6c2zgi8\n",
        "!gdown 1k-m84NIuOOTbXjn6ELwj1qBeH7jsN6IO\n",
        "!gdown 1-0Gg-qpqJpNfLPU7DT81UaFgwu8DVn15\n",
        "!unzip -q train_ende.zip\n",
        "!unzip -q dev.zip\n",
        "!unzip -q test.zip\n",
        "!mv train_ende train\n",
        "!mkdir train/image\n",
        "!mkdir dev/image\n",
        "!mkdir test/image\n",
        "!mv train/*.jpg train/image\n",
        "!mv dev/*.jpg dev/image\n",
        "!mv test/*.jpg test/image\n",
        "!mv *train.txt train\n",
        "!mv *dev.txt dev\n",
        "!mv *test.txt test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM987Bi4o2q2",
        "outputId": "1ee812a5-1855-471f-8fbe-aad36b43d77e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import nltk.tokenize as tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "import gc\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install -q transformers\n",
        "import seaborn as sns\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertModel\n",
        "from PIL import Image\n",
        "!pip install -q timm\n",
        "import timm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1HI_093VpCl1"
      },
      "outputs": [],
      "source": [
        "class MSCTD(Dataset):\n",
        "    \"\"\"\n",
        "    :param root: root path of the dataset\n",
        "    :param split: train, dev, test\n",
        "    :param image_transform: transform for image\n",
        "    :param text_transform: transform for text\n",
        "    :param sentiment_transform: transform for sentiment\n",
        "    :param has_data: dict, whether the dataset has image, text\n",
        "    :param text_path: path of the text file\n",
        "    :param image_path: path of the image folder\n",
        "    :param sentiment_path: path of the sentiment file\n",
        "    :param image_index_path: path of the image index file\n",
        "\n",
        "    :return: combination of image, sentiment, text, image_index\n",
        "\n",
        "    Example:\n",
        "    >>> from torchvision import transforms\n",
        "    >>> image_transform = transforms.Compose([\n",
        "    >>>     transforms.Resize((640, 1280)),\n",
        "    >>>     transforms.Lambda(lambda x: x.permute(1, 2, 0))\n",
        "    >>> ])\n",
        "    >>> text_transform = None\n",
        "    >>> sentiment_transform = None\n",
        "    >>> dataset = MSCTD(root='data', split='train', image_transform=image_transform,\n",
        "    >>>                 text_transform=text_transform, sentiment_transform=sentiment_transform)\n",
        "    >>> image, text, sentiment = dataset[0]\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, root, split, image_transform=None, text_transform=None, sentiment_transform=None,\n",
        "                 has_data={'image': True, 'text': True}, text_path=None, image_path=None, sentiment_path=None,\n",
        "                 image_index_path=None):\n",
        "        data_path = os.path.join(root, split)\n",
        "        default_path = {\n",
        "            'text': os.path.join(data_path, 'english_' + split + '.txt'),\n",
        "            'image': os.path.join(data_path, 'image'),\n",
        "            'sentiment': os.path.join(data_path, 'sentiment_' + split + '.txt'),\n",
        "            'image_index': os.path.join(data_path, 'image_index_' + split + '.txt'),\n",
        "        }\n",
        "        self.image = [] if has_data['image'] else None\n",
        "        self.image_transform = image_transform\n",
        "        self.image_path = image_path if image_path else default_path['image']\n",
        "        self.text = [] if has_data['text'] else None\n",
        "        self.text_transform = text_transform\n",
        "        self.text_path = text_path if text_path else default_path['text']\n",
        "        self.sentiment_path = sentiment_path if sentiment_path else default_path['sentiment']\n",
        "        self.image_index_path = image_index_path if image_index_path else default_path['image_index']\n",
        "        self.sentiment = []\n",
        "        self.image_index = []\n",
        "        self.sentiment_transform = sentiment_transform\n",
        "        self.load_data()\n",
        "        \n",
        "    def load_data(self):\n",
        "        self.sentiment = np.loadtxt(self.sentiment_path, dtype=int)\n",
        "        if self.text is not None:\n",
        "            with open(self.text_path, 'r') as f:\n",
        "                self.text = f.readlines()\n",
        "            self.text = [x.strip() for x in self.text]\n",
        "        with open(self.image_index_path, 'r') as f:\n",
        "            data = f.readlines()\n",
        "        self.image_index = [list(map(int, x[1:-2].split(','))) for x in data]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = None\n",
        "        text = None\n",
        "        sentiment = self.sentiment[index]\n",
        "        if self.image is not None:\n",
        "            imag_path = os.path.join(self.image_path, str(index)+'.jpg')\n",
        "            image = read_image(imag_path)\n",
        "            if self.image_transform:\n",
        "                image = self.image_transform(image)\n",
        "        if self.text is not None:\n",
        "            text = self.text[index]\n",
        "            if self.text_transform:\n",
        "                text = self.text_transform(text)\n",
        "        if self.sentiment_transform:\n",
        "            sentiment = self.sentiment_transform(sentiment)\n",
        "        if text is not None and image is not None:\n",
        "            return image, text, sentiment\n",
        "        elif text is not None:\n",
        "            return text, sentiment\n",
        "        elif image is not None:\n",
        "            return image, sentiment\n",
        "        else:\n",
        "            raise Exception('Either image or text should be not None')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OQr-lM0Epwx7"
      },
      "outputs": [],
      "source": [
        "image_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.Resize((224, 224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "MSCTD_train = MSCTD(root='.', split='train', image_transform=image_transform, has_data={'image': True, 'text': True})\n",
        "MSCTD_dev = MSCTD(root='.', split='dev', image_transform=image_transform, has_data={'image': True, 'text': True})\n",
        "MSCTD_test = MSCTD(root='.', split='test', image_transform=image_transform, has_data={'image': True, 'text': True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SklafdvXpxGn"
      },
      "outputs": [],
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character used by WordNetLemmatizer\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def text_preprocessor(dataset):\n",
        "      # preprocess text\n",
        "      dataset.text = [preprocess_text(text) for text in dataset.text]\n",
        "\n",
        "def preprocess_text(text):\n",
        "      # Replace contractions with original text\n",
        "  text = re.sub(r'(\\b[Aa]in\\'t\\b)', \"am not\", text)\n",
        "  text = re.sub(r'(\\b[Hh]a\\'t\\b)', \"has\", text)\n",
        "  text = re.sub(r'(\\b[Ii]\\'m\\b)', \"i am\", text)\n",
        "  text = re.sub(r'(\\b\\'s\\b)', \" is\", text)\n",
        "  text = re.sub(r'(\\b\\'re\\b)', \" are\", text)\n",
        "  text = re.sub(r'(\\b\\'ve\\b)', \" have\", text)\n",
        "  text = re.sub(r'(\\b\\'d\\b)', \" would\", text)\n",
        "  text = re.sub(r'(\\b\\'ll\\b)', \" will\", text)\n",
        "  text = re.sub(r'(\\b[Ss]han\\'t\\b)', \"shall not\", text)\n",
        "  text = re.sub(r'(\\b[Ww]on\\'t\\b)', \"will not\", text)\n",
        "  text = re.sub(r'(\\b[Ww]ouldn\\'t\\b)', \"would not\", text)\n",
        "  text = re.sub(r'(\\b[Dd]on\\'t\\b)', \"do not\", text)\n",
        "  text = re.sub(r'(\\b[Cc]an\\'t\\b)', \"can not\", text)\n",
        "  text = re.sub(r'(\\b[Ii]s\\'nt\\b)', \"is not\", text)\n",
        "  text = re.sub(r'(\\b[Ww]eren\\'t\\b)', \"were not\", text)\n",
        "  text = re.sub(r'(\\b[Hh]aven\\'t\\b)', \"have not\", text)\n",
        "  text = re.sub(r'(\\b[Hh]adn\\'t\\b)', \"had not\", text)\n",
        "  text = re.sub(r'(\\b[Hh]asn\\'t\\b)', \"has not\", text)\n",
        "  text = re.sub(r'(\\b[Hh]adn\\'t\\b)', \"had not\", text)\n",
        "  text = re.sub(r'(\\b[Dd]idn\\'t\\b)', \"did not\", text)\n",
        "\n",
        "  # Remove punctuation\n",
        "  text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "  # Convert to lowercase\n",
        "  text = text.lower()\n",
        "\n",
        "  # Tokenize text\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  # Remove stop words\n",
        "  # tokens = [token for token in tokens if token not in stop_words]\n",
        "  # Remove numbers\n",
        "  tokens = [token for token in tokens if token.isalpha()]\n",
        "\n",
        "  # Lemmatize tokens\n",
        "  tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
        "\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "# Test the TextPreprocessor\n",
        "text_preprocessor(MSCTD_train)\n",
        "text_preprocessor(MSCTD_dev)\n",
        "text_preprocessor(MSCTD_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 Subpart 1"
      ],
      "metadata": {
        "id": "Z7RYrMIrqY_2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jgwu_OxCor0"
      },
      "outputs": [],
      "source": [
        "# define a class that get a dataset and return tokenized dataset\n",
        "class TokenizedDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_length=80):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __getitem__(self, index):\n",
        "        image, text, sentiment = self.dataset[index]\n",
        "        text = self.tokenizer.encode_plus(text, add_special_tokens=True, max_length=self.max_length, \n",
        "                                          padding='max_length', truncation=True, return_tensors='pt')\n",
        "        return image, text, sentiment\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# define a image_encoder model using resnet50 on timm\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self, is_trainable=True):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        self.resnet = timm.create_model('resnet50', pretrained=True)\n",
        "        self.resnet.fc = nn.Identity()\n",
        "        if not is_trainable:\n",
        "            for param in self.resnet.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# define a text_encoder model using bert-base-uncased on huggingface\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, is_trainable=True):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        if not is_trainable:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = {k: v.squeeze(1) for k, v in x.items()}\n",
        "        return self.bert(**x).last_hidden_state[:, 0, :]\n",
        "\n",
        "# define a MLP classifier\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vgsrDe1eqaw",
        "outputId": "41332452-a2ec-40ab-8102-db319f673b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenize datasets\n",
        "max_length = 25\n",
        "tokenized_train = TokenizedDataset(MSCTD_train, tokenizer, max_length)\n",
        "tokenized_dev = TokenizedDataset(MSCTD_dev, tokenizer, max_length)\n",
        "tokenized_test = TokenizedDataset(MSCTD_test, tokenizer, max_length)\n",
        "\n",
        "# dataloader\n",
        "train_dataloader_tokenized = DataLoader(tokenized_train, batch_size=32, shuffle=True)\n",
        "dev_dataloader_tokenized = DataLoader(tokenized_dev, batch_size=32, shuffle=True)\n",
        "test_dataloader_tokenized = DataLoader(tokenized_test, batch_size=32, shuffle=True)\n",
        "\n",
        "# define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# define image_encoder and text_encoder\n",
        "image_encoder = ImageEncoder(is_trainable=False).to(device)\n",
        "text_encoder = TextEncoder(is_trainable=True).to(device)\n",
        "\n",
        "# define the classifier\n",
        "classifier = MLPClassifier(2048+768, 512, 3).to(device)\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = optim.Adam(list(text_encoder.parameters()) + list(classifier.parameters()), lr=1e-5)\n",
        "\n",
        "# define the loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQybwz-iVy5v",
        "outputId": "0e6770ca-94c6-46c4-f89e-b7f7c68d06e2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:51<00:00,  1.54it/s]\n",
            "100%|██████████| 159/159 [01:15<00:00,  2.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 0.9538, Train Acc: 0.5910, Dev Loss: 0.9388, Dev Acc: 0.6009\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:45<00:00,  1.56it/s]\n",
            "100%|██████████| 159/159 [01:15<00:00,  2.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Train Loss: 0.8611, Train Acc: 0.6849, Dev Loss: 0.9400, Dev Acc: 0.5941\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:44<00:00,  1.57it/s]\n",
            "100%|██████████| 159/159 [01:15<00:00,  2.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Train Loss: 0.8083, Train Acc: 0.7407, Dev Loss: 0.9394, Dev Acc: 0.6002\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:44<00:00,  1.56it/s]\n",
            "100%|██████████| 159/159 [01:16<00:00,  2.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Train Loss: 0.7710, Train Acc: 0.7789, Dev Loss: 0.9452, Dev Acc: 0.5964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:42<00:00,  1.57it/s]\n",
            "100%|██████████| 159/159 [01:15<00:00,  2.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Train Loss: 0.7523, Train Acc: 0.7981, Dev Loss: 0.9533, Dev Acc: 0.5897\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:42<00:00,  1.57it/s]\n",
            "100%|██████████| 159/159 [01:15<00:00,  2.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Train Loss: 0.7384, Train Acc: 0.8116, Dev Loss: 0.9532, Dev Acc: 0.5910\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:40<00:00,  1.58it/s]\n",
            "100%|██████████| 159/159 [01:14<00:00,  2.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Train Loss: 0.7278, Train Acc: 0.8227, Dev Loss: 0.9508, Dev Acc: 0.5924\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [06:41<00:00,  1.58it/s]\n",
            "100%|██████████| 159/159 [01:15<00:00,  2.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Train Loss: 0.7192, Train Acc: 0.8315, Dev Loss: 0.9619, Dev Acc: 0.5828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 633/633 [06:40<00:00,  1.58it/s]\n",
            "100%|██████████| 159/159 [01:14<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.7125, Train Acc: 0.8384, Dev Loss: 0.9559, Dev Acc: 0.5873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 633/633 [06:43<00:00,  1.57it/s]\n",
            "100%|██████████| 159/159 [01:15<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.7059, Train Acc: 0.8448, Dev Loss: 0.9546, Dev Acc: 0.5914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "dev_losses = []\n",
        "train_accs = []\n",
        "dev_accs = []\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # train\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    total_samples = 0\n",
        "    for images, texts, labels in tqdm(train_dataloader_tokenized):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        texts = texts.to(device)\n",
        "        # get the image and text embeddings\n",
        "        image_embeddings = image_encoder(images)\n",
        "        text_embeddings = text_encoder(texts)\n",
        "        # concatenate the image and text embeddings\n",
        "        embeddings = torch.cat((image_embeddings, text_embeddings), dim=1)\n",
        "        # get the predictions\n",
        "        predictions = classifier(embeddings)\n",
        "        # calculate the loss\n",
        "        loss = F.cross_entropy(predictions, labels)\n",
        "        # calculate the accuracy\n",
        "        acc = (predictions.argmax(dim=1) == labels).float().sum()\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # update the loss and accuracy\n",
        "        train_loss += loss.item()\n",
        "        train_acc += acc.item()\n",
        "        total_samples += labels.size(0)\n",
        "    # calculate the average loss and accuracy\n",
        "    train_loss /= len(train_dataloader_tokenized)\n",
        "    train_acc /= total_samples\n",
        "    # save the loss and accuracy\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    # evaluate\n",
        "    dev_loss = 0\n",
        "    dev_acc = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for images, texts, labels in tqdm(dev_dataloader_tokenized):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            texts = texts.to(device)\n",
        "            # get the image and text embeddings\n",
        "            image_embeddings = image_encoder(images)\n",
        "            text_embeddings = text_encoder(texts)\n",
        "            # concatenate the image and text embeddings\n",
        "            embeddings = torch.cat((image_embeddings, text_embeddings), dim=1)\n",
        "            # get the predictions\n",
        "            predictions = classifier(embeddings)\n",
        "            # calculate the loss\n",
        "            loss = F.cross_entropy(predictions, labels)\n",
        "            # calculate the accuracy\n",
        "            acc = (predictions.argmax(dim=1) == labels).float().sum()\n",
        "            # update the loss and accuracy\n",
        "            dev_loss += loss.item()\n",
        "            dev_acc += acc.item()\n",
        "            total_samples += labels.size(0)\n",
        "    # calculate the average loss and accuracy\n",
        "    dev_loss /= len(dev_dataloader_tokenized)\n",
        "    dev_acc /= total_samples\n",
        "    # save the loss and accuracy\n",
        "    dev_losses.append(dev_loss)\n",
        "    dev_accs.append(dev_acc)\n",
        "    # print the loss and accuracy\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCM5X2-_nxMT",
        "outputId": "c417055a-de7d-43c2-f88c-03031d99e731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the loss and accuracy\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax[0].plot(train_losses, label='train')\n",
        "ax[0].plot(dev_losses, label='dev')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].title.set_text('Loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(train_accs, label='train')\n",
        "ax[1].plot(dev_accs, label='dev')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].title.set_text('Accuracy')\n",
        "ax[1].legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "test_acc = 0\n",
        "total_samples = 0\n",
        "with torch.no_grad():\n",
        "    for images, texts, labels in tqdm(test_dataloader_tokenized):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        texts = texts.to(device)\n",
        "        # get the image and text embeddings\n",
        "        image_embeddings = image_encoder(images)\n",
        "        text_embeddings = text_encoder(texts)\n",
        "        # concatenate the image and text embeddings\n",
        "        embeddings = torch.cat((image_embeddings, text_embeddings), dim=1)\n",
        "        # get the predictions\n",
        "        predictions = classifier(embeddings)\n",
        "        # calculate the loss\n",
        "        loss = F.cross_entropy(predictions, labels)\n",
        "        # calculate the accuracy\n",
        "        acc = (predictions.argmax(dim=1) == labels).float().sum()\n",
        "        # update the loss and accuracy\n",
        "        test_loss += loss.item()\n",
        "        test_acc += acc.item()\n",
        "        total_samples += labels.size(0)\n",
        "# calculate the average loss and accuracy\n",
        "test_loss /= len(test_dataloader_tokenized)\n",
        "test_acc /= total_samples\n",
        "print(f\"Test loss: {test_loss}, Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "ZmJneEYgZ5_u",
        "outputId": "9ee88203-f60a-4523-e861-df1c0891281f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159/159 [01:21<00:00,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.9487387879089739, Test accuracy: 0.5983816854154332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 Subpart 2"
      ],
      "metadata": {
        "id": "m2syDwJUqiOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "6dkMwKatqmT7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a class that get a dataset and return tokenized dataset\n",
        "class TokenizedDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_length=80):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __getitem__(self, index):\n",
        "        image, text, sentiment = self.dataset[index]\n",
        "        text = self.tokenizer.encode_plus(text, add_special_tokens=True, max_length=self.max_length, \n",
        "                                          padding='max_length', truncation=True, return_tensors='pt')\n",
        "        return image, text, sentiment\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# define a image_encoder model using resnet50 on timm\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self, is_trainable=True):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "        self.vit.head = nn.Identity()\n",
        "        if not is_trainable:\n",
        "            for param in self.vit.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "# define a text_encoder model using bert-base-uncased on huggingface\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, is_trainable=True):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        if not is_trainable:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = {k: v.squeeze(1) for k, v in x.items()}\n",
        "        return self.bert(**x).last_hidden_state[:, 0, :]\n",
        "\n",
        "# define a MLP classifier\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "u4ea1OrzST0b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenize datasets\n",
        "max_length = 25\n",
        "tokenized_train = TokenizedDataset(MSCTD_train, tokenizer, max_length)\n",
        "tokenized_dev = TokenizedDataset(MSCTD_dev, tokenizer, max_length)\n",
        "tokenized_test = TokenizedDataset(MSCTD_test, tokenizer, max_length)\n",
        "\n",
        "# dataloader\n",
        "train_dataloader_tokenized = DataLoader(tokenized_train, batch_size=32, shuffle=True)\n",
        "dev_dataloader_tokenized = DataLoader(tokenized_dev, batch_size=32, shuffle=True)\n",
        "test_dataloader_tokenized = DataLoader(tokenized_test, batch_size=32, shuffle=True)\n",
        "\n",
        "# define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# define image_encoder and text_encoder\n",
        "image_encoder = ImageEncoder(is_trainable=True).to(device)\n",
        "text_encoder = TextEncoder(is_trainable=True).to(device)\n",
        "\n",
        "# define the classifier\n",
        "classifier = MLPClassifier(768+768, 512, 3).to(device)\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = optim.Adam(list(text_encoder.parameters()) + list(classifier.parameters()) + list(image_encoder.parameters()), lr=1e-5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu-SS9OVMkuw",
        "outputId": "9173e055-c44a-4a65-f82b-ad5edf643cb6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "dev_losses = []\n",
        "train_accs = []\n",
        "dev_accs = []\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # train\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    total_samples = 0\n",
        "    for images, texts, labels in tqdm(train_dataloader_tokenized):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        texts = texts.to(device)\n",
        "        # get the image and text embeddings\n",
        "        image_embeddings = image_encoder(images)\n",
        "        text_embeddings = text_encoder(texts)\n",
        "        # concatenate the image and text embeddings\n",
        "        embeddings = torch.cat((image_embeddings, text_embeddings), dim=1)\n",
        "        # get the predictions\n",
        "        predictions = classifier(embeddings)\n",
        "        # calculate the loss\n",
        "        loss = F.cross_entropy(predictions, labels)\n",
        "        # calculate the accuracy\n",
        "        acc = (predictions.argmax(dim=1) == labels).float().sum()\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # update the loss and accuracy\n",
        "        train_loss += loss.item()\n",
        "        train_acc += acc.item()\n",
        "        total_samples += labels.size(0)\n",
        "    # calculate the average loss and accuracy\n",
        "    train_loss /= len(train_dataloader_tokenized)\n",
        "    train_acc /= total_samples\n",
        "    # save the loss and accuracy\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    # evaluate\n",
        "    dev_loss = 0\n",
        "    dev_acc = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for images, texts, labels in tqdm(dev_dataloader_tokenized):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            texts = texts.to(device)\n",
        "            # get the image and text embeddings\n",
        "            image_embeddings = image_encoder(images)\n",
        "            text_embeddings = text_encoder(texts)\n",
        "            # concatenate the image and text embeddings\n",
        "            embeddings = torch.cat((image_embeddings, text_embeddings), dim=1)\n",
        "            # get the predictions\n",
        "            predictions = classifier(embeddings)\n",
        "            # calculate the loss\n",
        "            loss = F.cross_entropy(predictions, labels)\n",
        "            # calculate the accuracy\n",
        "            acc = (predictions.argmax(dim=1) == labels).float().sum()\n",
        "            # update the loss and accuracy\n",
        "            dev_loss += loss.item()\n",
        "            dev_acc += acc.item()\n",
        "            total_samples += labels.size(0)\n",
        "    # calculate the average loss and accuracy\n",
        "    dev_loss /= len(dev_dataloader_tokenized)\n",
        "    dev_acc /= total_samples\n",
        "    # save the loss and accuracy\n",
        "    dev_losses.append(dev_loss)\n",
        "    dev_accs.append(dev_acc)\n",
        "    # print the loss and accuracy\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-AP3RrEPanv",
        "outputId": "a8ae8681-5c89-4066-d52d-ea63c94820e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 633/633 [16:53<00:00,  1.60s/it]\n",
            "100%|██████████| 159/159 [01:58<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.9526, Train Acc: 0.5824, Dev Loss: 0.9367, Dev Acc: 0.6038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 633/633 [16:17<00:00,  1.54s/it]\n",
            "100%|██████████| 159/159 [01:54<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.8543, Train Acc: 0.6929, Dev Loss: 0.9460, Dev Acc: 0.5923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 7/633 [00:10<15:59,  1.53s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sESHe0jlTKCO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e2f775898ea1037b7c9eeca230f0f6a000b04cbdfbf9c82813024cd1951cbec6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}